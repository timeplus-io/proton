test_suite_name: two_level_global_aggr
tag: smoke
test_suite_config:
  setup:
    statements:
      - client: python
        query_type: table
        query: |
          drop stream if exists test_31_rstream;
      - client: python
        query_type: table
        exist: test_31_rstream
        exist_wait: 2
        wait: 1
        query: |
          create random stream if not exists test_31_rstream(i int default rand() % 100000 + 1, v string) settings eps=5000, interval_time=100;

  tests_2_run:
    ids_2_run:
      - all
    tags_2_run: []
    tags_2_skip:
      default:
        - todo
        - to_support
        - change
        - bug
        - sample
      cluster:
        - view
        - cluster_table_bug
comments: Tests covering the historical/streaming query with two level global aggregation smoke cases.

tests:
  - id: 0
    tags:
      - "two level"
      - "global aggr"
    name: two-level-global-aggr
    description: global aggregation query with two level hash table, convering stremaing and historical query
    steps:
      - statements:
        - client: python
          query_type: stream
          query_id: 3100
          depends_on_stream: test_31_rstream
          wait: 1
          query_end_timer: 5
          query: |
            with cte as (select i % 100 + 1 as key, count() from test_31_rstream group by key settings group_by_two_level_threshold=50, max_block_size=100) select count() from cte limit 1;

        - client: python
          query_type: table
          query_id: 3101
          depends_on_stream: test_31_rstream
          query: |
            with cte as (select i % 100 + 1 as key, count() from table(test_31_rstream) group by key settings group_by_two_level_threshold=50, max_block_size=100, max_events=10000) select count() from cte;

    expected_results:
      - query_id: '3100'
        expected_results:
          - [100]
      - query_id: '3101'
        expected_results:
          - [100]

  - id: 1
    tags:
      - "global aggr"
      - "emit changelog"
      - "changelog aggr"
    name: two-level-global-aggr
    description: global aggregation query with two level hash table, covering aggregating changelog and emit changelog 
    steps:
      - statements:
        - client: python
          query_type: stream
          query_id: 3100
          depends_on_stream: test_31_rstream
          query_end_timer: 5
          query: |
            with cte as (select i % 100 + 1 as key, count() from test_31_rstream group by key emit changelog settings group_by_two_level_threshold=50, max_block_size=100) select count() from cte limit 1;

        - client: python
          query_type: stream
          query_id: 3101
          depends_on_stream: test_31_rstream
          query_end_timer: 5
          query: |
            with cte1 as (select i % 100 + 1 as key from test_31_rstream), cte2 as (select key, count() from changelog(cte1, key) group by key emit changelog settings group_by_two_level_threshold=50, max_block_size=100) select count() from cte2 limit 1;

    expected_results:
      - query_id: '3100'
        expected_results:
          - [100]
      - query_id: '3101'
        expected_results:
          - [100]

  - id: 2
    tags:
      - "two level"
      - "global aggr"
      - "query_state"
    name: subscribe-and-recover-two-level-global-aggr
    description: subscribe to two level global aggregation query, then recover from checkpointed.
    steps:
      - statements:
        - client: python
          query_type: table
          query: |
            drop stream if exists test_31_multishards_stream;

        - client: python
          query_type: table
          exist: test_31_multishards_stream
          exist_wait: 2
          wait: 1
          query: |
            create stream if not exists test_31_multishards_stream(i int, v string) settings shards=3;

        - client: python
          query_type: table
          depends_on_stream: test_31_multishards_stream
          wait: 1
          query: |
            insert into test_31_multishards_stream(i, v) select i % 100 + 1, v from test_31_rstream settings max_block_size=100, max_events=10000;

        - client: python
          query_type: stream
          query_id: 3100
          depends_on_stream: test_31_multishards_stream
          query: |
            subscribe to with cte as (select i as key, count() from test_31_multishards_stream where _tp_time > earliest_ts() group by key settings group_by_two_level_threshold=50) select count() from cte settings checkpoint_interval=2;

        - client: python
          query_type: table
          depends_on: 3100
          wait: 6
          query: |
            kill query where query_id = '3100' sync;

        - client: python
          query_type: table
          depends_on_stream: test_31_multishards_stream
          wait: 2
          query: |
            insert into test_31_multishards_stream(i, v) values(101, 'test');

        - client: python
          query_type: stream
          query_id: 3100-1
          depends_on_stream: test_31_multishards_stream
          wait: 2
          query: |
            recover from '3100';

        - client: python
          query_table: table
          wait: 5
          query: |
            unsubscribe to '3100';

    expected_results:
      - query_id: '3100'
        expected_results:
          - [100]
      - query_id: '3100-1'
        expected_results:
          - [101]

  - id: 3
    tags:
      - "two level"
      - "global aggr"
      - "emit changelog"
      - "changelog aggr"
      - "query_state"
      - "bug"
    name: subscribe-and-recover-two-level-global-aggr
    description: subscribe to two level global aggregation query, then recover from checkpointed.
    steps:
      - statements:
        - client: python
          query_type: table
          query: |
            drop stream if exists test_31_multishards_stream;

        - client: python
          query_type: table
          exist: test_31_multishards_stream
          exist_wait: 2
          wait: 1
          query: |
            create stream if not exists test_31_multishards_stream(i int, v string) settings shards=3;

        - client: python
          query_type: table
          depends_on_stream: test_31_multishards_stream
          wait: 1
          query: |
            insert into test_31_multishards_stream(i, v) select i % 100 + 1, v from test_31_rstream settings max_block_size=100, max_events=10000;

        - client: python
          query_type: stream
          query_id: 3101
          depends_on_stream: test_31_multishards_stream
          wait: 1
          query: |
            subscribe to with cte as (select i as key, count() from changelog(test_31_multishards_stream, i) where _tp_time > earliest_ts() group by key emit changelog settings group_by_two_level_threshold=50) select count() from cte settings checkpoint_interval=2;

        - client: python
          query_type: table
          depends_on: 3101
          wait: 6
          query: |
            kill query where query_id = '3101' sync;

        - client: python
          query_type: table
          wait: 1
          query: |
            insert into test_31_multishards_stream(i, v) values(101, 'test');

        - client: python
          query_type: stream
          query_id: 3101-1
          wait: 1
          query: |
            recover from '3101';

        - client: python
          query_table: table
          wait: 5
          query: |
            unsubscribe to '3101';

    expected_results:
      - query_id: '3101'
        expected_results:
          - [100]
      - query_id: '3101-1'
        expected_results:
          - [101]

  - id: 4
    tags:
      - "global aggr"
      - "shuffle by"
    name: global-aggr-with-shuffle-by
    description: global aggregation query with shuffle by, convering stremaing and historical query, by default disable convert to two level
    steps:
      - statements:
        - client: python
          query_type: table
          query: |
            drop stream if exists test_31_multishards_stream;

        - client: python
          query_type: table
          exist: test_31_multishards_stream
          exist_wait: 2
          wait: 1
          query: |
            create stream if not exists test_31_multishards_stream(i int, v string) settings shards=3;

        - client: python
          query_type: table
          depends_on_stream: test_31_multishards_stream
          wait: 1
          query: |
            insert into test_31_multishards_stream(i, v) select i % 100 + 1, v from test_31_rstream settings max_block_size=100, max_events=10000;

        - client: python
          query_type: stream
          query_id: 3100
          depends_on_stream: test_31_multishards_stream
          wait: 1
          query_end_timer: 5
          query: |
            with cte as (select i, count() from test_31_multishards_stream where _tp_time > earliest_ts() shuffle by i group by i settings group_by_two_level_threshold=10) select count() from cte settings emit_during_backfill=false;

        - client: python
          query_type: table
          query_id: 3101
          depends_on_stream: test_31_multishards_stream
          query: |
            with cte as (select i, count() from table(test_31_multishards_stream) shuffle by i group by i settings group_by_two_level_threshold=10, max_block_size=100, max_events=10000) select count() from cte;

    expected_results:
      - query_id: '3100'
        expected_results:
          - [100]
      - query_id: '3101'
        expected_results:
          - [100]

  - id: 5
    tags:
      - "global aggr"
      - "max blocksize"
      - "single level"
    name: global-aggr-with-max-blocksize
    description: single level global aggregation query with max block size
    steps:
      - statements:
        - client: python
          query_type: table
          query: |
            drop stream if exists test_31_stream;

        - client: python
          query_type: table
          exist: test_31_stream
          exist_wait: 2
          wait: 1
          query: |
            create stream if not exists test_31_stream(i int);

        - client: python
          query_type: table
          depends_on_stream: test_31_stream
          wait: 1
          query: |
            insert into test_31_stream(i) select number from numbers(5);

        - client: python
          query_type: stream
          query_id: 3100
          depends_on_stream: test_31_stream
          wait: 1
          query_end_timer: 5
          query: |
            select block_size() /* <= max_block_size+1 */ from test_31_stream where _tp_time > earliest_ts() group by i settings max_block_size=1;

    expected_results:
      - query_id: '3100'
        expected_results:
          - [2]
          - [2]

          - [2]
          - [2]

          - [1]