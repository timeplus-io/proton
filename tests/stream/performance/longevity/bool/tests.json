{
    "comments":
        "Tests covering the steam query smoke cases.",
    "test_suite_config": {
        "proton_ci_mode": "local",
        "table_schemas":[

            {
                "name": "ttp_state",
                "type": "table",
                "reset": "False",
                "query_parameters":"logstore_retention_ms=3600000",
                "config": "setting_1",
                "columns": [
                    {
                        "name": "lpn",
                        "type": "string"
                    },
                    {
                        "name": "windowStart",
                        "type": "datetime64(3, 'UTC')"
                    },
                    {
                        "name": "windowEnd",
                        "type": "datetime64(3, 'UTC')"
                    }, 
                    {
                        "name": "state",
                        "type": "string"
                    },
                    {
                        "name": "avg_speed",
                        "type": "float64"
                    },
                    {
                        "name": "last_speed",
                        "type": "float32"
                    },
                    {
                        "name": "lat",
                        "type": "float32"
                    },
                    {
                        "name": "lon",
                        "type": "float32"
                    },                                        
                    {
                        "name": "perf_event_time",
                        "type": "datetime64(3, 'Asia/Shanghai')",
                        "default": "now64(3, 'Asia/Shanghai')"
                    },                      
                    {
                        "name": "_perf_row_id",
                        "type": "string"
                    },                  
                    {
                        "name": "_perf_ingest_time",
                        "type": "string"
                    }
                ],
                "ttl_expression": "to_datetime(_tp_time) + INTERVAL 1 HOUR"
            }                       


        ],
        "setup": {

        },
        "tests_2_run": {"ids_2_run": [8], "tags_2_run":[], "tags_2_skip":["bug", "todo", "to_support"]} 
    },

    "tests": [


        {
            "id": 7,
            "tags": ["debug-ingestion only"],
            "name": "longevity - proton, with query time easy json volume, 80 streams",
            "description": "tail query latency w/single source",
            "db_engine":"proton",
            "input_info_table": "input_info",
            "steps":[
                {"statements": [
                    {"client":"python","config_set": "setting_1","workers": 2, "interval":1, "query_type": "table", "query":"drop view if exists ttp_state_v$"},                    
                    {"client":"python","config_set": "setting_1","workers": 2, "interval":1, "query_type": "table", "query":"drop stream if exists ttp_state_$"},
                    {"client":"python","config_set": "setting_1","workers": 2, "interval":1, "query_type": "table", "query":"CREATE STREAM if not exists ttp_state_$(`lpn` string, `windowStart` datetime64(3, 'UTC'), `windowEnd` datetime64(3, 'UTC'), `state` string, `avg_speed` float64, `last_speed` float32, `lat` float32, `lon` float32, perf_event_time datetime64(3) default now64(3,'Asia/Shanghai'), _perf_row_id string, _perf_ingest_time string) TTL to_datetime(_tp_time) + INTERVAL 24 HOUR SETTINGS logstore_retention_bytes = '21474836480', logstore_retention_ms = '00000'"},                    
                    {"client":"python", "config_set": "setting_1", "wait": 10, "query_id": 302, "run_mode":"process", "loop_times": 1, "workers": 5, "query_type": "stream", "terminate":"auto", "query_end_timer": 30, "query":"SELECT window_start,window_end, count_if(state='OFF') as off FROM tumble(ttp_state_0,10s) group by window_start, window_end EMIT timeout 10s", "result_keep":"False", "query_result_table":"query_result_03", "query_record_table":"query_record_01"},
                    {"client":"python","config_set": "setting_1","workers": 1,"query_id": 304, "interval":1, "loop_times": -1, "query_type": "table", "query":"select count_if(state='OFF') as off from table(ttp_state_0)"}

                ]},
                    

                {"inputs": [
                    {"table_name": "ttp_state_$","input_id": 311,"table_schema_ref":"ttp_state", "client":"rest", "workers":2, "data_source":"file", "data_set_path":"ttp_state", "data_set_file": "ttp_state.csv", "random_fields": "lpn","table_schema_file":"table_schema.json -todo", 
                        "ingest_interval":1,"interval_model":"random - todo", "time_incre_interval":0.5, "data_set_play_mode":"sequence", "rows_2_play": 100, "batch_size":1, "loop_times":-1, "result_keep":"False","input_record_table":"input_record"}

                ]}

            ]               
        },        
 
        {
            "id": 8,
            "tags": ["debug"],
            "name": "longevity - proton, with query time easy json volume, 80 streams",
            "description": "tail query latency w/single source",
            "db_engine":"proton",
            "input_info_table": "input_info",
            "steps":[
                {"statements": [
                    {"client":"python","config_set": "setting_1","workers": 2, "interval":1, "query_type": "table", "query":"drop view if exists ttp_state_v$"},                    
                    {"client":"python","config_set": "setting_1","workers": 2, "interval":1, "query_type": "table", "query":"drop stream if exists ttp_state_$"},
                    {"client":"python","config_set": "setting_1","workers": 2, "interval":1, "query_type": "table", "query":"CREATE STREAM if not exists ttp_state_$(`lpn` string, `windowStart` datetime64(3, 'UTC'), `windowEnd` datetime64(3, 'UTC'), `state` string, `avg_speed` float64, `last_speed` float32, `lat` float32, `lon` float32, perf_event_time datetime64(3) default now64(3,'Asia/Shanghai'), _perf_row_id string, _perf_ingest_time string) TTL to_datetime(_tp_time) + INTERVAL 24 HOUR SETTINGS logstore_retention_bytes = '21474836480', logstore_retention_ms = '00000'"},                    
                    {"client":"python", "config_set": "setting_1", "wait": 10, "query_id": 302, "run_mode":"process", "loop_times": 1, "workers": 5, "query_type": "stream", "terminate":"auto", "query_end_timer": 30, "query":"SELECT window_start,window_end, count_if(state='OFF') as off FROM tumble(ttp_state_0,10s) group by window_start, window_end EMIT timeout 10s", "result_keep":"False", "query_result_table":"query_result_03", "query_record_table":"query_record_01"},
                    {"client":"python","config_set": "setting_1","workers": 1,"query_id": 304, "interval":1, "loop_times": -1, "query_type": "table", "query":"select count_if(state='OFF') as off from table(ttp_state_0)"}

                ]},
                    

                {"inputs": [
                    {"table_name": "ttp_state_$","input_id": 310,"table_schema_ref":"ttp_state", "workers":2, "data_source":"file", "data_set_path":"ttp_state", "data_set_file": "ttp_state.csv", "random_fields": "lpn", "random_ranges":"2000", "table_schema_file":"table_schema.json -todo", 
                        "ingest_interval":1,"interval_model":"random - todo", "time_incre_interval":0.5, "data_set_play_mode":"sequence", "rows_2_play": 3000, "batch_size":5, "loop_times":-1, "result_keep":"False","input_record_table":"input_record"},
                    {"table_name": "ttp_state_$","input_id": 311,"table_schema_ref":"ttp_state", "client":"rest", "workers":2, "data_source":"file", "data_set_path":"ttp_state", "data_set_file": "ttp_state.csv", "random_fields": "lpn","table_schema_file":"table_schema.json -todo", 
                        "ingest_interval":1,"interval_model":"random - todo", "time_incre_interval":0.5, "data_set_play_mode":"sequence", "rows_2_play": 100, "batch_size":1, "loop_times":-1, "result_keep":"False","input_record_table":"input_record"},
                    {"table_name": "ttp_state_$","input_id": 312,"table_schema_ref":"ttp_state", "$start_from": 0,"$end_at":1, "client":"rest", "workers":2,"worker_mode":"round_robin", "data_source":"file", "data_set_path":"ttp_state", "data_set_file": "ttp_state.csv","random_fields": "lpn", "table_schema_file":"table_schema.json -todo", 
                        "ingest_interval":1,"interval_model":"random - todo", "time_incre_interval":0.5, "data_set_play_mode":"sequence", "rows_2_play": 100, "batch_size":1, "loop_times":-1, "result_keep":"False","input_record_table":"input_record"}

                ]}

            ]               
        }              
        
                                       

    ]
}


